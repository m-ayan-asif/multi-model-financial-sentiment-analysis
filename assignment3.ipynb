{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c0bce2",
   "metadata": {},
   "source": [
    "FinBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb3c7f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "import os, random, numpy as np, torch\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109396a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Coding\\\\Uni\\\\DLP\\\\Assignment3\\\\dataset\\\\FinancialPhraseBank-v1.0\\\\Sentences_50Agree.txt',\n",
       " 'c:\\\\Coding\\\\Uni\\\\DLP\\\\Assignment3\\\\dataset\\\\FinancialPhraseBank-v1.0\\\\Sentences_66Agree.txt',\n",
       " 'c:\\\\Coding\\\\Uni\\\\DLP\\\\Assignment3\\\\dataset\\\\FinancialPhraseBank-v1.0\\\\Sentences_75Agree.txt',\n",
       " 'c:\\\\Coding\\\\Uni\\\\DLP\\\\Assignment3\\\\dataset\\\\FinancialPhraseBank-v1.0\\\\Sentences_AllAgree.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset_dir = \"dataset\\FinancialPhraseBank-v1.0\\.\" \n",
    "files = [\n",
    "    \"Sentences_50Agree.txt\",\n",
    "    \"Sentences_66Agree.txt\",\n",
    "    \"Sentences_75Agree.txt\",\n",
    "    \"Sentences_AllAgree.txt\"\n",
    "]\n",
    "\n",
    "folder = os.path.abspath(dataset_dir)\n",
    "files = [os.path.join(folder, f) for f in files]\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df84275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Sentences_50Agree.txt: 100%|██████████| 4846/4846 [00:00<00:00, 537500.92it/s]\n",
      "Loading Sentences_66Agree.txt: 100%|██████████| 4217/4217 [00:00<00:00, 587620.60it/s]\n",
      "Loading Sentences_75Agree.txt: 100%|██████████| 3453/3453 [00:00<00:00, 427868.82it/s]\n",
      "Loading Sentences_AllAgree.txt: 100%|██████████| 2264/2264 [00:00<00:00, 501156.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  According to Gran , the company has no plans t...   neutral\n",
       "1  Technopolis plans to develop in stages an area...   neutral\n",
       "2  The international electronic industry company ...  negative\n",
       "3  With the new production plant the company woul...  positive\n",
       "4  According to the company 's updated strategy f...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for fp in files:\n",
    "    with open(fp, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        lines = f.read().splitlines()   #avoiding line by line I/O\n",
    "    \n",
    "    for line in tqdm(lines, desc=f\"Loading {os.path.basename(fp)}\"):\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        \n",
    "        match = re.search(r\"@(positive|negative|neutral)$\", line)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        label = match.group(1)\n",
    "        text = line[:line.rfind(\"@\")].strip()\n",
    "\n",
    "        texts.append(text)\n",
    "        labels.append(label)\n",
    "\n",
    "df = pd.DataFrame({\"text\": texts, \"label\": labels})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800a0e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "neutral     8951\n",
       "positive    3988\n",
       "negative    1841\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n",
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c739d975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>according gran company plans move production r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>technopolis plans develop stages area less 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>international electronic industry company elco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>positive</td>\n",
       "      <td>new production plant company would increase ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>according company updated strategy years 2009 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0  According to Gran , the company has no plans t...   neutral   \n",
       "1  Technopolis plans to develop in stages an area...   neutral   \n",
       "2  The international electronic industry company ...  negative   \n",
       "3  With the new production plant the company woul...  positive   \n",
       "4  According to the company 's updated strategy f...  positive   \n",
       "\n",
       "                                          clean_text  \n",
       "0  according gran company plans move production r...  \n",
       "1  technopolis plans develop stages area less 100...  \n",
       "2  international electronic industry company elco...  \n",
       "3  new production plant company would increase ca...  \n",
       "4  according company updated strategy years 2009 ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "STOP = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_text(t):\n",
    "    t = str(t).lower()\n",
    "    t = re.sub(r\"http\\S+\", \" \", t)\n",
    "    t = re.sub(r\"[^a-z0-9\\s]\", \" \", t)\n",
    "    tokens = [w for w in t.split() if w not in STOP and len(w) > 2]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bff815de",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m38\u001b[39m, \u001b[38;5;241m45\u001b[39m]:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m---> 12\u001b[0m     lda \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLdaModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mid2word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     coherence \u001b[38;5;241m=\u001b[39m CoherenceModel(\n\u001b[0;32m     20\u001b[0m         model\u001b[38;5;241m=\u001b[39mlda,\n\u001b[0;32m     21\u001b[0m         texts\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m     22\u001b[0m         dictionary\u001b[38;5;241m=\u001b[39mdictionary,\n\u001b[0;32m     23\u001b[0m         coherence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_v\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     24\u001b[0m     )\u001b[38;5;241m.\u001b[39mget_coherence()\n\u001b[0;32m     26\u001b[0m     results[k] \u001b[38;5;241m=\u001b[39m coherence\n",
      "File \u001b[1;32mc:\\Users\\Ayan\\miniconda3\\envs\\fintext\\lib\\site-packages\\gensim\\models\\ldamodel.py:522\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    520\u001b[0m use_numpy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    521\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 522\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks_as_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_numpy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    525\u001b[0m     msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    526\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Ayan\\miniconda3\\envs\\fintext\\lib\\site-packages\\gensim\\models\\ldamodel.py:1007\u001b[0m, in \u001b[0;36mLdaModel.update\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1003\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   1004\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROGRESS: pass \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m, at document #\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1005\u001b[0m         pass_, chunk_no \u001b[38;5;241m*\u001b[39m chunksize \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk), lencorpus\n\u001b[0;32m   1006\u001b[0m     )\n\u001b[1;32m-> 1007\u001b[0m     gammat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_estep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_alpha:\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_alpha(gammat, rho())\n",
      "File \u001b[1;32mc:\\Users\\Ayan\\miniconda3\\envs\\fintext\\lib\\site-packages\\gensim\\models\\ldamodel.py:769\u001b[0m, in \u001b[0;36mLdaModel.do_estep\u001b[1;34m(self, chunk, state)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m--> 769\u001b[0m gamma, sstats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect_sstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m state\u001b[38;5;241m.\u001b[39msstats \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sstats\n\u001b[0;32m    771\u001b[0m state\u001b[38;5;241m.\u001b[39mnumdocs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m gamma\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# avoids calling len(chunk) on a generator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ayan\\miniconda3\\envs\\fintext\\lib\\site-packages\\gensim\\models\\ldamodel.py:723\u001b[0m, in \u001b[0;36mLdaModel.inference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    721\u001b[0m Elogthetad \u001b[38;5;241m=\u001b[39m dirichlet_expectation(gammad)\n\u001b[0;32m    722\u001b[0m expElogthetad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(Elogthetad)\n\u001b[1;32m--> 723\u001b[0m phinorm \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpElogthetad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpElogbetad\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m epsilon\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If gamma hasn't changed much, we're done.\u001b[39;00m\n\u001b[0;32m    725\u001b[0m meanchange \u001b[38;5;241m=\u001b[39m mean_absolute_difference(gammad, lastgamma)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "texts = [t.split() for t in df[\"clean_text\"]]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(t) for t in texts]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for k in [35, 38, 45]:\n",
    "    ...\n",
    "    lda = models.LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=k,\n",
    "        random_state=42,\n",
    "        passes=10\n",
    "    )\n",
    "    coherence = CoherenceModel(\n",
    "        model=lda,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence=\"c_v\"\n",
    "    ).get_coherence()\n",
    "    \n",
    "    results[k] = coherence\n",
    "    print(f\"k = {k}, coherence = {coherence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a93f1fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.046*\"well\" + 0.046*\"products\" + 0.032*\"finland\" + 0.032*\"services\" + 0.026*\"service\" + 0.023*\"research\" + 0.020*\"customers\" + 0.017*\"facilities\" + 0.016*\"meat\" + 0.016*\"network\"')\n",
      "(1, '0.033*\"whole\" + 0.028*\"paid\" + 0.022*\"personnel\" + 0.019*\"negotiations\" + 0.017*\"cut\" + 0.016*\"also\" + 0.015*\"electricity\" + 0.015*\"information\" + 0.014*\"date\" + 0.014*\"content\"')\n",
      "(2, '0.047*\"posted\" + 0.041*\"100\" + 0.026*\"aldata\" + 0.021*\"solution\" + 0.021*\"holding\" + 0.019*\"corporate\" + 0.019*\"planned\" + 0.018*\"cover\" + 0.015*\"next\" + 0.015*\"retail\"')\n",
      "(3, '0.077*\"oyj\" + 0.065*\"finnish\" + 0.061*\"said\" + 0.049*\"today\" + 0.040*\"hel\" + 0.038*\"approximately\" + 0.036*\"000\" + 0.033*\"million\" + 0.031*\"usd\" + 0.027*\"2010\"')\n",
      "(4, '0.037*\"company\" + 0.022*\"director\" + 0.020*\"line\" + 0.018*\"kemira\" + 0.018*\"finnish\" + 0.016*\"business\" + 0.015*\"managing\" + 0.014*\"finland\" + 0.013*\"product\" + 0.013*\"maintenance\"')\n",
      "(5, '0.054*\"investment\" + 0.046*\"eur\" + 0.039*\"value\" + 0.030*\"company\" + 0.022*\"scanfil\" + 0.020*\"dropped\" + 0.017*\"basware\" + 0.017*\"added\" + 0.017*\"terms\" + 0.012*\"properties\"')\n",
      "(6, '0.056*\"finland\" + 0.033*\"ceo\" + 0.019*\"said\" + 0.019*\"published\" + 0.015*\"helsinki\" + 0.013*\"cargo\" + 0.013*\"sweden\" + 0.013*\"czech\" + 0.013*\"according\" + 0.012*\"president\"')\n",
      "(7, '0.025*\"stora\" + 0.023*\"business\" + 0.022*\"enso\" + 0.021*\"november\" + 0.021*\"north\" + 0.016*\"america\" + 0.016*\"going\" + 0.016*\"rental\" + 0.015*\"finnish\" + 0.013*\"department\"')\n",
      "(8, '0.058*\"operations\" + 0.043*\"cash\" + 0.031*\"russia\" + 0.026*\"flow\" + 0.023*\"trade\" + 0.023*\"activities\" + 0.019*\"representing\" + 0.018*\"cost\" + 0.017*\"said\" + 0.015*\"cutting\"')\n",
      "(9, '0.042*\"media\" + 0.028*\"project\" + 0.024*\"scheduled\" + 0.022*\"system\" + 0.022*\"alma\" + 0.022*\"company\" + 0.018*\"ltd\" + 0.016*\"major\" + 0.016*\"india\" + 0.014*\"building\"')\n",
      "(10, '0.022*\"said\" + 0.022*\"countries\" + 0.018*\"stake\" + 0.015*\"company\" + 0.015*\"economic\" + 0.014*\"swedish\" + 0.013*\"baltic\" + 0.012*\"olvi\" + 0.012*\"target\" + 0.011*\"group\"')\n",
      "(11, '0.066*\"mobile\" + 0.058*\"services\" + 0.036*\"electronics\" + 0.028*\"contract\" + 0.026*\"elcoteq\" + 0.024*\"manufacturing\" + 0.023*\"software\" + 0.016*\"manufacturer\" + 0.015*\"concerning\" + 0.014*\"finnish\"')\n",
      "(12, '0.036*\"market\" + 0.034*\"issued\" + 0.031*\"situation\" + 0.021*\"following\" + 0.019*\"transferred\" + 0.018*\"persons\" + 0.016*\"decision\" + 0.015*\"outlook\" + 0.015*\"maximum\" + 0.015*\"development\"')\n",
      "(13, '0.026*\"financial\" + 0.021*\"purchase\" + 0.017*\"acquired\" + 0.015*\"wood\" + 0.015*\"banks\" + 0.014*\"mainly\" + 0.014*\"company\" + 0.014*\"new\" + 0.014*\"systems\" + 0.013*\"aspo\"')\n",
      "(14, '0.073*\"share\" + 0.066*\"per\" + 0.054*\"eur0\" + 0.041*\"earnings\" + 0.040*\"eps\" + 0.035*\"amounted\" + 0.026*\"eur1\" + 0.025*\"capman\" + 0.023*\"internet\" + 0.022*\"financial\"')\n",
      "(15, '0.067*\"plant\" + 0.044*\"expected\" + 0.038*\"start\" + 0.034*\"production\" + 0.025*\"equipment\" + 0.021*\"related\" + 0.018*\"units\" + 0.018*\"water\" + 0.018*\"completed\" + 0.016*\"end\"')\n",
      "(16, '0.125*\"shares\" + 0.056*\"share\" + 0.052*\"capital\" + 0.043*\"board\" + 0.037*\"rights\" + 0.036*\"number\" + 0.031*\"company\" + 0.027*\"voting\" + 0.025*\"total\" + 0.023*\"directors\"')\n",
      "(17, '0.039*\"news\" + 0.033*\"reported\" + 0.027*\"prices\" + 0.022*\"business\" + 0.020*\"combined\" + 0.020*\"afx\" + 0.019*\"due\" + 0.018*\"marimekko\" + 0.018*\"finnish\" + 0.018*\"equity\"')\n",
      "(18, '0.033*\"transaction\" + 0.026*\"international\" + 0.025*\"costs\" + 0.025*\"finland\" + 0.022*\"company\" + 0.022*\"energy\" + 0.018*\"outotec\" + 0.015*\"operations\" + 0.014*\"group\" + 0.012*\"industry\"')\n",
      "(19, '0.040*\"real\" + 0.026*\"estate\" + 0.024*\"company\" + 0.023*\"currently\" + 0.011*\"technology\" + 0.011*\"street\" + 0.011*\"public\" + 0.010*\"order\" + 0.010*\"underground\" + 0.010*\"new\"')\n",
      "(20, '0.039*\"billion\" + 0.035*\"unit\" + 0.031*\"order\" + 0.026*\"revenue\" + 0.022*\"said\" + 0.017*\"slightly\" + 0.016*\"paper\" + 0.014*\"ebit\" + 0.013*\"one\" + 0.012*\"short\"')\n",
      "(21, '0.048*\"deal\" + 0.034*\"area\" + 0.021*\"group\" + 0.021*\"nordic\" + 0.020*\"company\" + 0.019*\"results\" + 0.017*\"food\" + 0.014*\"talentum\" + 0.013*\"business\" + 0.013*\"companies\"')\n",
      "(22, '0.032*\"printing\" + 0.027*\"range\" + 0.023*\"center\" + 0.019*\"private\" + 0.018*\"handset\" + 0.017*\"told\" + 0.017*\"home\" + 0.016*\"estimate\" + 0.016*\"charging\" + 0.015*\"located\"')\n",
      "(23, '0.164*\"eur\" + 0.074*\"profit\" + 0.050*\"net\" + 0.047*\"mln\" + 0.046*\"operating\" + 0.043*\"quarter\" + 0.041*\"period\" + 0.032*\"sales\" + 0.030*\"2007\" + 0.028*\"year\"')\n",
      "(24, '0.063*\"value\" + 0.059*\"total\" + 0.035*\"contract\" + 0.033*\"part\" + 0.031*\"long\" + 0.030*\"estimated\" + 0.023*\"group\" + 0.022*\"business\" + 0.021*\"term\" + 0.019*\"insurance\"')\n",
      "(25, '0.047*\"stock\" + 0.035*\"turnover\" + 0.026*\"com\" + 0.022*\"place\" + 0.021*\"company\" + 0.019*\"www\" + 0.019*\"options\" + 0.018*\"power\" + 0.017*\"decreased\" + 0.017*\"option\"')\n",
      "(26, '0.036*\"construction\" + 0.028*\"ruukki\" + 0.024*\"industry\" + 0.020*\"margin\" + 0.020*\"communication\" + 0.019*\"mill\" + 0.018*\"pulp\" + 0.017*\"steel\" + 0.017*\"building\" + 0.016*\"teleste\"')\n",
      "(27, '0.081*\"totalled\" + 0.043*\"result\" + 0.028*\"level\" + 0.024*\"company\" + 0.023*\"consumer\" + 0.021*\"remain\" + 0.016*\"previous\" + 0.015*\"2008\" + 0.014*\"hkscan\" + 0.013*\"received\"')\n",
      "(28, '0.069*\"nokia\" + 0.028*\"operations\" + 0.023*\"networks\" + 0.020*\"office\" + 0.019*\"packaging\" + 0.019*\"germany\" + 0.017*\"continuing\" + 0.015*\"siemens\" + 0.015*\"owns\" + 0.011*\"corporation\"')\n",
      "(29, '0.131*\"market\" + 0.049*\"price\" + 0.047*\"share\" + 0.027*\"markets\" + 0.027*\"data\" + 0.024*\"global\" + 0.016*\"included\" + 0.015*\"analysis\" + 0.014*\"bank\" + 0.013*\"london\"')\n",
      "(30, '0.123*\"sales\" + 0.059*\"net\" + 0.042*\"pct\" + 0.029*\"increase\" + 0.027*\"expects\" + 0.026*\"company\" + 0.023*\"lower\" + 0.020*\"2009\" + 0.020*\"2006\" + 0.019*\"expected\"')\n",
      "(31, '0.126*\"million\" + 0.091*\"year\" + 0.087*\"percent\" + 0.041*\"euros\" + 0.036*\"sales\" + 0.030*\"last\" + 0.017*\"x20ac\" + 0.016*\"chairman\" + 0.014*\"grew\" + 0.014*\"earlier\"')\n",
      "(32, '0.079*\"bank\" + 0.071*\"fell\" + 0.054*\"non\" + 0.043*\"items\" + 0.038*\"excluding\" + 0.036*\"recurring\" + 0.031*\"oil\" + 0.022*\"facility\" + 0.020*\"finland\" + 0.018*\"nordea\"')\n",
      "(33, '0.050*\"helsinki\" + 0.046*\"september\" + 0.036*\"2008\" + 0.033*\"2010\" + 0.031*\"company\" + 0.031*\"march\" + 0.030*\"omx\" + 0.029*\"corporation\" + 0.028*\"january\" + 0.024*\"finnish\"')\n",
      "(34, '0.103*\"000\" + 0.030*\"per\" + 0.029*\"negative\" + 0.024*\"cent\" + 0.022*\"vice\" + 0.020*\"capacity\" + 0.020*\"would\" + 0.019*\"tonnes\" + 0.018*\"production\" + 0.014*\"made\"')\n"
     ]
    }
   ],
   "source": [
    "best_k = 35\n",
    "lda = models.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=best_k,\n",
    "    random_state=42,\n",
    "    passes=10\n",
    ")\n",
    "\n",
    "topics = lda.print_topics(num_topics=best_k, num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "df[\"topic\"] = [\n",
    "    max(lda.get_document_topics(bow), key=lambda x: x[1])[0]\n",
    "    for bow in corpus\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719a9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Preds: 14780\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "\n",
    "finbert_name = \"ProsusAI/finbert\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(finbert_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    finbert_name,\n",
    "    trust_remote_code=True,\n",
    "    use_safetensors=True\n",
    ")\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "finbert = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    top_k=1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "def predict_finbert(batch):\n",
    "    outputs = finbert(batch, top_k=1)\n",
    "\n",
    "    preds = []\n",
    "    for out in outputs:\n",
    "        # case 1: dict\n",
    "        if isinstance(out, dict):\n",
    "            preds.append(out[\"label\"].lower())\n",
    "        # case 2: [{'label':..., 'score':...}]\n",
    "        elif isinstance(out, list) and len(out) and isinstance(out[0], dict):\n",
    "            preds.append(out[0][\"label\"].lower())\n",
    "        # case 3: [[{'label':...}]]\n",
    "        elif isinstance(out, list) and len(out) and isinstance(out[0], list):\n",
    "            preds.append(out[0][0][\"label\"].lower())\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected output format:\", out)\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "batch_size = 32   \n",
    "preds = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df[\"text\"].iloc[i:i+batch_size].tolist()\n",
    "    p = predict_finbert(batch)\n",
    "    preds.extend(p)\n",
    "\n",
    "df[\"finbert_pred\"] = preds\n",
    "print(\"Done! Preds:\", len(preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76015596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinBERT Accuracy: 0.9236129905277402\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.98      0.90      1841\n",
      "     neutral       0.98      0.90      0.94      8951\n",
      "    positive       0.86      0.94      0.90      3988\n",
      "\n",
      "    accuracy                           0.92     14780\n",
      "   macro avg       0.89      0.94      0.91     14780\n",
      "weighted avg       0.93      0.92      0.92     14780\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1800   19   22]\n",
      " [ 288 8084  579]\n",
      " [  70  151 3767]]\n",
      "Confusion Matrix:\n",
      " [[1800   19   22]\n",
      " [ 288 8084  579]\n",
      " [  70  151 3767]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_true = df[\"label\"]\n",
    "y_pred = df[\"finbert_pred\"]\n",
    "\n",
    "print(\"FinBERT Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print()\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "print()\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3939e03",
   "metadata": {},
   "source": [
    "Local LLM Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "972f4c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "llm = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"cross-encoder/nli-deberta-v3-base\",\n",
    "    device=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "783f9df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"negative\", \"neutral\", \"positive\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e5a3a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! LLM preds: 14780\n"
     ]
    }
   ],
   "source": [
    "def predict_llm(batch):\n",
    "    outputs = llm(batch, candidate_labels=labels)\n",
    "    preds = [out[\"labels\"][0] for out in outputs]\n",
    "    return preds\n",
    "\n",
    "batch_size = 8\n",
    "llm_preds = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df[\"text\"].iloc[i:i+batch_size].tolist()\n",
    "    p = predict_llm(batch)\n",
    "    llm_preds.extend(p)\n",
    "\n",
    "df[\"llm_pred\"] = llm_preds\n",
    "print(\"Done! LLM preds:\", len(llm_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3535fc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Accuracy: 0.6877537212449256\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.90      0.75      1841\n",
      "     neutral       0.81      0.66      0.72      8951\n",
      "    positive       0.54      0.66      0.59      3988\n",
      "\n",
      "    accuracy                           0.69     14780\n",
      "   macro avg       0.66      0.74      0.69     14780\n",
      "weighted avg       0.71      0.69      0.69     14780\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1661  176    4]\n",
      " [ 795 5878 2278]\n",
      " [ 115 1247 2626]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_true = df[\"label\"]\n",
    "y_pred = df[\"llm_pred\"]\n",
    "\n",
    "print(\"LLM Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print()\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "print()\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65806177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LLM2: 14780\n",
      "0.3439106901217862\n"
     ]
    }
   ],
   "source": [
    "llm2 = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"typeform/distilbert-base-uncased-mnli\",\n",
    "    device=0\n",
    ")\n",
    "\n",
    "def predict_llm2(batch):\n",
    "    outputs = llm2(batch, candidate_labels=[\"negative\",\"neutral\",\"positive\"])\n",
    "    return [o[\"labels\"][0] for o in outputs]\n",
    "\n",
    "batch_size = 8\n",
    "llm2_preds = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df[\"text\"].iloc[i:i+batch_size].tolist()\n",
    "    llm2_preds.extend(predict_llm2(batch))\n",
    "\n",
    "df[\"llm2_pred\"] = llm2_preds\n",
    "print(\"Done with LLM2:\", len(llm2_preds))\n",
    "\n",
    "print(accuracy_score(df[\"label\"], df[\"llm2_pred\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c1a3d",
   "metadata": {},
   "source": [
    "RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc7ad190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG parameters and imports\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "\n",
    "EMB_MODEL_NAME = \"all-MiniLM-L6-v2\"   # fast, good\n",
    "EMB_BATCH_SIZE = 128\n",
    "FAISS_INDEX_PATH = \"faiss_index.idx\"\n",
    "EMBS_PATH = \"embs.npy\"\n",
    "\n",
    "RAG_K = 5            # retrieval depth (try 3,5,10 experiments)\n",
    "RAG_BATCH = 32       # how many queries per LLM batch\n",
    "CANDIDATE_LABELS = [\"negative\", \"neutral\", \"positive\"]  # same labels as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "606d4e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings (this may take a couple minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 116/116 [00:02<00:00, 40.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built. n: 14780\n"
     ]
    }
   ],
   "source": [
    "# encode all clean_text into embeddings and build FAISS index (CPU)\n",
    "embedder = SentenceTransformer(EMB_MODEL_NAME)\n",
    "\n",
    "print(\"Computing embeddings (this may take a couple minutes)...\")\n",
    "embs = embedder.encode(df[\"clean_text\"].tolist(), convert_to_numpy=True, show_progress_bar=True, batch_size=EMB_BATCH_SIZE)\n",
    "np.save(EMBS_PATH, embs)\n",
    "\n",
    "# normalize for cosine similarity\n",
    "faiss.normalize_L2(embs)\n",
    "d = embs.shape[1]\n",
    "index = faiss.IndexFlatIP(d)   # inner product on normalized vectors == cosine similarity\n",
    "index.add(embs)\n",
    "faiss.write_index(index, FAISS_INDEX_PATH)\n",
    "print(\"FAISS index built. n:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52a6f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_topk(sentence_idx, k=RAG_K):\n",
    "    # returns indices and distances for the given sentence index in dataset\n",
    "    q = embs[sentence_idx:sentence_idx+1]  # already normalized\n",
    "    D, I = index.search(q, k)\n",
    "    return I[0].tolist(), D[0].tolist()\n",
    "\n",
    "# robust RAG classifier for a batch of input sentences\n",
    "def rag_classify_batch(query_texts, query_indices, k=RAG_K):\n",
    "    \"\"\"\n",
    "    query_texts: list[str] - the original (untokenized) sentences to classify\n",
    "    query_indices: list[int] - indices into df that correspond to query_texts (for retrieval base)\n",
    "    returns: list[str] predicted labels\n",
    "    \"\"\"\n",
    "    prompts = []\n",
    "    for q_text, q_idx in zip(query_texts, query_indices):\n",
    "        # retrieve top-k neighbors for context (exclude the query itself if it's the same index)\n",
    "        I, D = retrieve_topk(q_idx, k=k)\n",
    "        # optionally remove the first result if it's the query itself\n",
    "        context_sentences = []\n",
    "        for idx in I:\n",
    "            if idx == q_idx:\n",
    "                continue\n",
    "            context_sentences.append(df[\"text\"].iloc[idx])\n",
    "        # build context string (short)\n",
    "        context = \"\\n\".join(context_sentences[:k]) if context_sentences else \"\"\n",
    "        # final prompt: include context then the target sentence\n",
    "        full_input = f\"Context:\\n{context}\\n\\nSentence:\\n{q_text}\\n\\nClassify the sentiment of the Sentence as NEGATIVE / NEUTRAL / POSITIVE.\"\n",
    "        prompts.append(full_input)\n",
    "    # call zero-shot classifier (batch)\n",
    "    outputs = llm(prompts, candidate_labels=CANDIDATE_LABELS)\n",
    "    # outputs: list of dicts; pick top label\n",
    "    preds = [out[\"labels\"][0] for out in outputs]\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "019b8f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAG inference in batches. This will take several minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [19:06<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG done. preds: 14780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a mapping of indices to text for query (we will classify every sentence using its own index)\n",
    "n = len(df)\n",
    "rag_preds = []\n",
    "batch_size = RAG_BATCH\n",
    "\n",
    "print(\"Running RAG inference in batches. This will take several minutes.\")\n",
    "\n",
    "for i in tqdm(range(0, n, batch_size)):\n",
    "    batch_indices = list(range(i, min(i+batch_size, n)))\n",
    "    batch_texts = df[\"text\"].iloc[batch_indices].tolist()\n",
    "    # call rag classifier\n",
    "    batch_preds = rag_classify_batch(batch_texts, batch_indices, k=RAG_K)\n",
    "    rag_preds.extend(batch_preds)\n",
    "\n",
    "# attach to dataframe\n",
    "df[\"rag_pred\"] = rag_preds\n",
    "print(\"RAG done. preds:\", len(rag_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7e230d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Accuracy: 0.18606224627875506\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.13      0.96      0.24      1841\n",
      "     neutral       0.71      0.05      0.10      8951\n",
      "    positive       0.52      0.13      0.21      3988\n",
      "\n",
      "    accuracy                           0.19     14780\n",
      "   macro avg       0.45      0.38      0.18     14780\n",
      "weighted avg       0.58      0.19      0.14     14780\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1772   54   15]\n",
      " [8021  464  466]\n",
      " [3335  139  514]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_true = df[\"label\"]\n",
    "y_pred = df[\"rag_pred\"]\n",
    "\n",
    "print(\"RAG Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print()\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "print()\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ed77d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved df CSV and FAISS index and embeddings.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"with_rag_predictions.csv\", index=False)\n",
    "faiss.write_index(index, FAISS_INDEX_PATH)\n",
    "np.save(EMBS_PATH, embs)\n",
    "print(\"Saved df CSV and FAISS index and embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5fa9fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAG results with k=3\n",
      "Accuracy: 0.1604871447902571\n",
      "\n",
      "RAG results with k=10\n",
      "Accuracy: 0.17550744248985115\n"
     ]
    }
   ],
   "source": [
    "for k in [3, 10]:\n",
    "    RAG_K = k\n",
    "    rag_preds_k = []\n",
    "\n",
    "    for i in range(0, len(df), 32):\n",
    "        batch = df[\"text\"].iloc[i:i+32].tolist()\n",
    "        idx_batch = list(range(i, min(i+32, len(df))))\n",
    "        rag_preds_k.extend(rag_classify_batch(batch, idx_batch, k=RAG_K))\n",
    "\n",
    "    print(f\"\\nRAG results with k={k}\")\n",
    "    print(\"Accuracy:\", accuracy_score(df[\"label\"], rag_preds_k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "946b2146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns: []\n",
      "Saved resultsWithAllModels.csv with 14780 rows.\n"
     ]
    }
   ],
   "source": [
    "required_cols = [\"finbert_pred\", \"llm_pred\", \"llm2_pred\", \"rag_pred\"]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "print(\"Missing columns:\", missing)\n",
    "\n",
    "#Save combined results\n",
    "df.to_csv(\"resultsWithAllModels.csv\", index=False)\n",
    "print(\"Saved resultsWithAllModels.csv with\", len(df), \"rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f27e8473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cm_finbert.png\n",
      "Saved cm_llm1.png\n",
      "Saved cm_llm2.png\n",
      "Saved cm_rag.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Make images look consistent\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "def save_cm(y_true, y_pred, filename, title):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[\"negative\", \"neutral\", \"positive\"])\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm,\n",
    "                annot=True,\n",
    "                fmt=\"d\",\n",
    "                cmap=\"Blues\",\n",
    "                xticklabels=[\"negative\", \"neutral\", \"positive\"],\n",
    "                yticklabels=[\"negative\", \"neutral\", \"positive\"])\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved {filename}\")\n",
    "\n",
    "# === Generate all confusion matrices ===\n",
    "\n",
    "save_cm(df[\"label\"], df[\"finbert_pred\"], \"cm_finbert.png\", \"FinBERT Confusion Matrix\")\n",
    "save_cm(df[\"label\"], df[\"llm_pred\"],     \"cm_llm1.png\",   \"LLM1 (DeBERTa NLI) Confusion Matrix\")\n",
    "save_cm(df[\"label\"], df[\"llm2_pred\"],    \"cm_llm2.png\",   \"LLM2 (DistilBERT MNLI) Confusion Matrix\")\n",
    "save_cm(df[\"label\"], df[\"rag_pred\"],     \"cm_rag.png\",    \"RAG-Based Sentiment Confusion Matrix\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
